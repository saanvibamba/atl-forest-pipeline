{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed8c06d",
   "metadata": {},
   "source": [
    "# Cell 0: Environment & Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0810dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, importlib, pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "USE_WIDGETS   = int(os.getenv(\"USE_WIDGETS\", \"0\"))\n",
    "ENABLE_ACTIVE = int(os.getenv(\"ENABLE_ACTIVE\", \"0\"))\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "DATA_RAW     = (PROJECT_ROOT / \"data\" / \"raw\").resolve()\n",
    "DATA_PROC    = (PROJECT_ROOT / \"data\" / \"processed\").resolve()\n",
    "RESULTS_ROOT = (PROJECT_ROOT / \"results\").resolve()\n",
    "for d in (DATA_RAW, DATA_PROC, RESULTS_ROOT):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _enable_inline():\n",
    "    get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "def _enable_widget():\n",
    "    get_ipython().run_line_magic(\"matplotlib\", \"widget\")\n",
    "\n",
    "widgets_enabled = False\n",
    "if USE_WIDGETS:\n",
    "    try:\n",
    "        import ipywidgets, ipympl \n",
    "        _enable_widget()\n",
    "        widgets_enabled = True\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] USE_WIDGETS=1 but ipywidgets/ipympl not available \"\n",
    "              f\"({e.__class__.__name__}). Falling back to inline.\")\n",
    "        _enable_inline()\n",
    "else:\n",
    "    _enable_inline()\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "def _ver(modname):\n",
    "    try:\n",
    "        m = importlib.import_module(modname)\n",
    "        return getattr(m, \"__version__\", \"unknown\")\n",
    "    except Exception as e:\n",
    "        return f\"missing ({e.__class__.__name__})\"\n",
    "\n",
    "print(\"=== Environment ===\")\n",
    "print(\"Time:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"Matplotlib backend:\", matplotlib.get_backend())\n",
    "print(\"Widgets enabled:\", widgets_enabled)\n",
    "print(\"numpy:\", _ver(\"numpy\"))\n",
    "print(\"opencv-python (cv2):\", _ver(\"cv2\"))\n",
    "print(\"scikit-image:\", _ver(\"skimage\"))\n",
    "print(\"scikit-learn:\", _ver(\"sklearn\"))\n",
    "print(\"ipywidgets:\", _ver(\"ipywidgets\"))\n",
    "print(\"ipympl:\", _ver(\"ipympl\"))\n",
    "print(\"\\nDATA_RAW:\", str(DATA_RAW))\n",
    "print(\"DATA_PROC:\", str(DATA_PROC))\n",
    "print(\"RESULTS_ROOT:\", str(RESULTS_ROOT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49fe227",
   "metadata": {},
   "source": [
    "# Cell 1: Paths & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d4c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, numpy as np, matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(PROJECT_ROOT)\n",
    "DATA_RAW     = Path(DATA_RAW)\n",
    "DATA_PROC    = Path(DATA_PROC)\n",
    "RESULTS_ROOT = Path(RESULTS_ROOT)\n",
    "\n",
    "for d in [DATA_RAW, DATA_PROC, RESULTS_ROOT]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"RAW:\", str(DATA_RAW))\n",
    "print(\"PROC:\", str(DATA_PROC))\n",
    "print(\"RESULTS:\", str(RESULTS_ROOT))\n",
    "\n",
    "if not DATA_RAW.is_dir():\n",
    "    raise FileNotFoundError(f\"RAW directory not found: {DATA_RAW}\")\n",
    "\n",
    "VALID_EXT = (\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".bmp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1606c7e9",
   "metadata": {},
   "source": [
    "# Cell 2: Load & Preview Raw Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = []  \n",
    "print(f\"Using DATA_RAW: {DATA_RAW}\")\n",
    "fnames = sorted([p.name for p in DATA_RAW.iterdir() if p.suffix.lower() in VALID_EXT])\n",
    "print(f\"Found {len(fnames)} image(s)\")\n",
    "\n",
    "for fname in fnames:\n",
    "    path = DATA_RAW / fname\n",
    "    img_bgr = cv2.imread(str(path), cv2.IMREAD_COLOR)  \n",
    "    if img_bgr is None:\n",
    "        print(f\"[warn] failed to read {path}, skipping.\")\n",
    "        continue\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    images.append((fname, img_rgb))\n",
    "\n",
    "print(f\"Loaded {len(images)} image(s).\")\n",
    "\n",
    "n = len(images)\n",
    "if n:\n",
    "    show_n = min(n, 9)\n",
    "    cols = min(3, show_n)\n",
    "    rows = int(np.ceil(show_n/cols))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "    axes = np.atleast_1d(axes).ravel()\n",
    "    for ax, (fname, img) in zip(axes, images[:show_n]):\n",
    "        ax.imshow(img); ax.set_title(fname); ax.axis(\"off\")\n",
    "    for ax in axes[show_n:]:\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"[note] No images loaded — add files to data/raw and re-run.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b7020",
   "metadata": {},
   "source": [
    "# Cell 3: Preprocess (Grayscale, Resize, Equalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf52a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert 'images' in globals() and len(images) > 0, \"Run Cell 2 first to populate `images`.\"\n",
    "\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TARGET_SIZE = (512, 512)\n",
    "\n",
    "preprocessed = []\n",
    "\n",
    "for fname, img_rgb in images:\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    gray_resized = cv2.resize(gray, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    gray_blur = cv2.GaussianBlur(gray_resized, (3, 3), 0)\n",
    "    gray_eq = cv2.equalizeHist(gray_blur)\n",
    "\n",
    "    preprocessed.append((fname, gray_eq))\n",
    "    cv2.imwrite(str(PROCESSED_DIR / f\"{Path(fname).stem}_gray_eq.png\"), gray_eq)\n",
    "\n",
    "print(f\"Preprocessed {len(preprocessed)} image(s) → {PROCESSED_DIR}\")\n",
    "\n",
    "n = len(preprocessed)\n",
    "cols = min(3, max(1, int(math.ceil(n**0.5))))\n",
    "rows = int(math.ceil(n / cols))\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "for ax, (fname, gray_eq) in zip(axes, preprocessed):\n",
    "    ax.imshow(gray_eq, cmap=\"gray\")\n",
    "    ax.set_title(f\"{fname} • preprocessed\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "for ax in axes[len(preprocessed):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eaddcf",
   "metadata": {},
   "source": [
    "# Cell 3.5: Utilities & Feature Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, cv2\n",
    "\n",
    "try:\n",
    "    from skimage.filters import rank\n",
    "    from skimage.morphology import disk\n",
    "    _HAS_SKIMAGE = True\n",
    "except Exception:\n",
    "    _HAS_SKIMAGE = False\n",
    "\n",
    "def ensure_uint8(img):\n",
    "    if img.dtype != np.uint8:\n",
    "        return np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def feature_stack(img_rgb, gray):\n",
    "    \"\"\"\n",
    "    Build HxWxF feature cube aligned to the preprocessed gray size (H,W).\n",
    "    Features: [gray, r_n, g_n, b_n, VI_proxy, laplacian, grad_mag, entropy_or_var]\n",
    "    \"\"\"\n",
    "    gray = ensure_uint8(gray)\n",
    "    H, W = gray.shape[:2]\n",
    "\n",
    "    if img_rgb.ndim == 2:\n",
    "        img_rgb = np.stack([img_rgb]*3, axis=-1)\n",
    "    elif img_rgb.shape[2] == 4:\n",
    "        img_rgb = img_rgb[..., :3]\n",
    "    elif img_rgb.shape[2] == 1:\n",
    "        img_rgb = np.concatenate([img_rgb]*3, axis=-1)\n",
    "    else:\n",
    "        img_rgb = img_rgb[..., :3]\n",
    "\n",
    "    if img_rgb.shape[:2] != (H, W):\n",
    "        img_rgb = cv2.resize(img_rgb, (W, H), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    rgb = img_rgb.astype(np.float32)\n",
    "    s = np.maximum(rgb.sum(axis=2), 1e-6)\n",
    "    r_n = rgb[..., 0] / s\n",
    "    g_n = rgb[..., 1] / s\n",
    "    b_n = rgb[..., 2] / s\n",
    "\n",
    "    vi = (rgb[..., 1] - rgb[..., 0]) / (rgb[..., 1] + rgb[..., 0] + 1e-6)\n",
    "\n",
    "    lap  = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)\n",
    "    sobx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    soby = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    grad = np.hypot(sobx, soby)\n",
    "\n",
    "    if _HAS_SKIMAGE:\n",
    "        ent = rank.entropy(ensure_uint8(gray), disk(5)).astype(np.float32)\n",
    "    else:\n",
    "        ent = cv2.blur((cv2.Laplacian(gray, cv2.CV_32F, ksize=3) ** 2), (5, 5))\n",
    "\n",
    "    F = np.dstack([\n",
    "        gray.astype(np.float32),\n",
    "        r_n.astype(np.float32), g_n.astype(np.float32), b_n.astype(np.float32),\n",
    "        vi.astype(np.float32), lap, grad, ent\n",
    "    ])\n",
    "    return F\n",
    "\n",
    "def clean_mask(mask, min_area=200, k=3):\n",
    "    m = (mask > 0).astype(np.uint8) * 255\n",
    "    kernel = np.ones((k, k), np.uint8)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN,  kernel, iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    num, lab, stats, _ = cv2.connectedComponentsWithStats((m > 0).astype(np.uint8), connectivity=8)\n",
    "    out = np.zeros_like(m)\n",
    "    for i in range(1, num):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            out[lab == i] = 255\n",
    "    out = cv2.medianBlur(out, 3)\n",
    "    return out\n",
    "\n",
    "def get_gray_eq(fname):\n",
    "    for f, g in preprocessed:\n",
    "        if f == fname:\n",
    "            return g\n",
    "    raise KeyError(f\"No preprocessed gray for {fname}\")\n",
    "\n",
    "FEATURES = {}\n",
    "if not images:\n",
    "    print(\"No images found; feature cache skipped.\")\n",
    "else:\n",
    "    for fname, img_rgb in images:\n",
    "        F = feature_stack(img_rgb, get_gray_eq(fname))\n",
    "        FEATURES[fname] = (F,) + F.shape\n",
    "    print(f\"Cached features for {len(FEATURES)} images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05f601",
   "metadata": {},
   "source": [
    "# Cell 4: Baseline Forest Classification – Thresholding (Otsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_THRESH = os.path.join(RESULTS_ROOT, \"thresholding\")\n",
    "os.makedirs(RESULTS_THRESH, exist_ok=True)\n",
    "\n",
    "otsu_results = []\n",
    "for fname, gray_eq in preprocessed:\n",
    "    _, otsu = cv2.threshold(gray_eq, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    if (otsu > 0).sum() / otsu.size < 0.3:\n",
    "        otsu = 255 - otsu\n",
    "    otsu_results.append((fname, otsu))\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title(f\"Otsu: {fname}\")\n",
    "    plt.imshow(otsu, cmap=\"gray\"); plt.axis(\"off\")\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    cv2.imwrite(os.path.join(RESULTS_THRESH, f\"{os.path.splitext(fname)[0]}_otsu.png\"), otsu)\n",
    "\n",
    "print(f\"Otsu masks saved to: {RESULTS_THRESH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a3c21",
   "metadata": {},
   "source": [
    "# Cell 5: Baseline Canny + Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_EDGES = os.path.join(RESULTS_ROOT, \"edges\")\n",
    "os.makedirs(RESULTS_EDGES, exist_ok=True)\n",
    "\n",
    "edges_results = []\n",
    "for fname, gray_eq in preprocessed:\n",
    "    edges = cv2.Canny(gray_eq, 100, 200)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    mask = cv2.dilate(edges, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    edges_results.append((fname, mask))\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "    ax[0].set_title(f\"Canny: {fname}\"); ax[0].imshow(edges, cmap=\"gray\"); ax[0].axis(\"off\")\n",
    "    ax[1].set_title(\"Edge Region Mask\"); ax[1].imshow(mask,  cmap=\"gray\"); ax[1].axis(\"off\")\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    cv2.imwrite(os.path.join(RESULTS_EDGES, f\"{os.path.splitext(fname)[0]}_edges_mask.png\"), mask)\n",
    "\n",
    "print(f\"Edge-region masks saved to: {RESULTS_EDGES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2844f82",
   "metadata": {},
   "source": [
    "# Cell 6: Baseline Forest Classification – K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "RESULTS_KMEANS = os.path.join(RESULTS_ROOT, \"kmeans\")\n",
    "os.makedirs(RESULTS_KMEANS, exist_ok=True)\n",
    "\n",
    "kmeans_results = []\n",
    "for fname, img_rgb in images:\n",
    "    gray_eq = get_gray_eq(fname)\n",
    "    F = feature_stack(img_rgb, gray_eq)\n",
    "    H, W, C = F.shape\n",
    "    X = F.reshape(-1, C)\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "\n",
    "    km = KMeans(n_clusters=2, n_init=10, random_state=42).fit(Xs)\n",
    "    lab = km.labels_.reshape(H, W)\n",
    "\n",
    "    r_n = F[...,1]; vi = F[...,4]\n",
    "    m_vi0 = vi[lab==0].mean() if (lab==0).any() else -1e9\n",
    "    m_vi1 = vi[lab==1].mean() if (lab==1).any() else -1e9\n",
    "    forest_label = 0 if m_vi0 > m_vi1 else 1\n",
    "\n",
    "    mask = (lab == forest_label).astype(np.uint8)*255\n",
    "    mask = clean_mask(mask)\n",
    "\n",
    "    kmeans_results.append((fname, mask))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title(f\"K-Means (forest): {fname}\")\n",
    "    plt.imshow(mask, cmap=\"gray\"); plt.axis(\"off\")\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    cv2.imwrite(os.path.join(RESULTS_KMEANS, f\"{os.path.splitext(fname)[0]}_kmeans_forest.png\"), mask)\n",
    "\n",
    "print(f\"K-Means masks saved to: {RESULTS_KMEANS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7c51c",
   "metadata": {},
   "source": [
    "# Cell 7: Side-By-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428f72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "otsu_map = {f: m for f, m in otsu_results}\n",
    "edge_map = {f: m for f, m in edges_results}\n",
    "km_map   = {f: m for f, m in kmeans_results}\n",
    "\n",
    "shown = 0\n",
    "for fname, img_rgb in images:\n",
    "    if (fname not in otsu_map) or (fname not in edge_map) or (fname not in km_map):\n",
    "        print(f\"[skip] {fname}: missing a baseline result.\")\n",
    "        continue\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 5), constrained_layout=True)\n",
    "    axs[0].imshow(img_rgb);            axs[0].set_title(f\"Original: {fname}\"); axs[0].axis(\"off\")\n",
    "    axs[1].imshow(otsu_map[fname],  cmap=\"gray\"); axs[1].set_title(\"Otsu\");         axs[1].axis(\"off\")\n",
    "    axs[2].imshow(edge_map[fname],  cmap=\"gray\"); axs[2].set_title(\"Canny+Morph\");  axs[2].axis(\"off\")\n",
    "    axs[3].imshow(km_map[fname],    cmap=\"gray\"); axs[3].set_title(\"K-Means\");      axs[3].axis(\"off\")\n",
    "\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "    shown += 1\n",
    "\n",
    "print(f\"Displayed {shown} comparison figure(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552759e",
   "metadata": {},
   "source": [
    "# Cell 8: Quantitative Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861bc3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_fraction(mask):\n",
    "    return (mask > 0).sum() / mask.size\n",
    "\n",
    "print(\"Forest pixel fraction (per method):\\n\")\n",
    "for fname, _ in images:\n",
    "    if (fname not in otsu_map) or (fname not in edge_map) or (fname not in km_map):\n",
    "        continue\n",
    "    print(fname)\n",
    "    print(\"  Otsu   :\", round(forest_fraction(otsu_map[fname]), 3))\n",
    "    print(\"  Canny  :\", round(forest_fraction(edge_map[fname]), 3))\n",
    "    print(\"  K-Means:\", round(forest_fraction(km_map[fname]), 3))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3d864",
   "metadata": {},
   "source": [
    "# Cell 9: Auto Generated Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "N_POS, N_NEG = 60, 60\n",
    "SEED  = 42\n",
    "rng   = np.random.default_rng(SEED)\n",
    "\n",
    "def to_bin(m): return (m > 0).astype(np.uint8)\n",
    "def interior(m, k=3, iters=1):\n",
    "    m = m.astype(np.uint8)\n",
    "    kern = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k,k))\n",
    "    return cv2.erode(m, kern, iterations=iters)\n",
    "def open_thin(m, k=3, iters=1):\n",
    "    m = m.astype(np.uint8)\n",
    "    kern = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k,k))\n",
    "    return cv2.morphologyEx(m, cv2.MORPH_OPEN, kern, iterations=iters)\n",
    "def sample_coords(mask_bin, n, rng):\n",
    "    ys, xs = np.where(mask_bin > 0)\n",
    "    if ys.size == 0 or n <= 0: return []\n",
    "    n = min(n, ys.size)\n",
    "    idx = rng.choice(ys.size, size=n, replace=False)\n",
    "    return list(zip(xs[idx], ys[idx]))\n",
    "def crop_border_mask(h, w, pad_px):\n",
    "    keep = np.zeros((h, w), np.uint8)\n",
    "    keep[pad_px:h-pad_px, pad_px:w-pad_px] = 1\n",
    "    return keep\n",
    "\n",
    "otsu_map = {f: m for f, m in otsu_results}\n",
    "km_map   = {f: m for f, m in kmeans_results}\n",
    "\n",
    "CLICK_SAMPLES = []  \n",
    "total_pos = total_neg = 0\n",
    "\n",
    "for fname, _ in images:\n",
    "    if fname not in otsu_map or fname not in km_map:\n",
    "        print(f\"[warn] {fname}: missing masks; skipping.\")\n",
    "        continue\n",
    "\n",
    "    A = to_bin(km_map[fname])\n",
    "    B = to_bin(otsu_map[fname])\n",
    "\n",
    "    H = min(A.shape[0], B.shape[0]); W = min(A.shape[1], B.shape[1])\n",
    "    A, B = A[:H, :W], B[:H, :W]\n",
    "\n",
    "    pad = max(10, int(0.03 * min(H, W)))\n",
    "    keep = crop_border_mask(H, W, pad)\n",
    "    A &= keep; B &= keep\n",
    "\n",
    "    I  = (A & B).astype(np.uint8)       \n",
    "    K  = (A & (~B)).astype(np.uint8)    \n",
    "    O  = (B & (~A)).astype(np.uint8)    \n",
    "    BG = (~(A | B)).astype(np.uint8)    \n",
    "\n",
    "    I  = open_thin(I, 3, 1)\n",
    "    K  = open_thin(K, 3, 1)\n",
    "    O  = open_thin(O, 3, 1)\n",
    "    BG = open_thin(BG, 3, 1)\n",
    "\n",
    "    nI, nK = N_POS // 2, N_POS - (N_POS // 2)\n",
    "    nBG, nO = N_NEG // 2, N_NEG - (N_NEG // 2)\n",
    "\n",
    "    pos = sample_coords(interior(I, 3, 1), nI,  rng) + sample_coords(interior(K, 3, 1), nK, rng)\n",
    "    neg = sample_coords(interior(BG,3, 1), nBG, rng) + sample_coords(interior(O, 3, 1), nO, rng)\n",
    "\n",
    "    if len(pos) < N_POS:\n",
    "        pos_all = interior((A | B).astype(np.uint8), 3, 1)\n",
    "        pos += sample_coords(pos_all, N_POS - len(pos), rng)\n",
    "    if len(neg) < N_NEG:\n",
    "        neg_all = interior((BG | O).astype(np.uint8), 3, 1)\n",
    "        neg += sample_coords(neg_all, N_NEG - len(neg), rng)\n",
    "\n",
    "    if len(pos) == 0 or len(neg) == 0:\n",
    "        print(f\"[warn] {fname}: not enough candidates; skipping.\")\n",
    "        continue\n",
    "\n",
    "    for (x, y) in pos[:N_POS]:\n",
    "        CLICK_SAMPLES.append({\"fname\": fname, \"x\": int(x), \"y\": int(y), \"label\": 1, \"source\": \"auto\"})\n",
    "    for (x, y) in neg[:N_NEG]:\n",
    "        CLICK_SAMPLES.append({\"fname\": fname, \"x\": int(x), \"y\": int(y), \"label\": 0, \"source\": \"auto\"})\n",
    "\n",
    "    total_pos += min(len(pos), N_POS)\n",
    "    total_neg += min(len(neg), N_NEG)\n",
    "    print(f\"{fname}: +{min(len(pos), N_POS)} pos, +{min(len(neg), N_NEG)} neg\")\n",
    "\n",
    "print(f\"\\nAuto-generated clicks total: {total_pos} pos, {total_neg} neg (~{N_POS}+{N_NEG} per image)\")\n",
    "\n",
    "(PROJECT_ROOT / \"data\").mkdir(parents=True, exist_ok=True)\n",
    "CLICKS_PATH = PROJECT_ROOT / \"data\" / \"training_clicks.json\"\n",
    "with open(str(CLICKS_PATH), \"w\") as f:\n",
    "    json.dump(CLICK_SAMPLES, f)\n",
    "print(\"Saved to:\", str(CLICKS_PATH))\n",
    "print(\"CLICK_SAMPLES in RAM:\", len(CLICK_SAMPLES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a9e6f",
   "metadata": {},
   "source": [
    "# Cell 10: Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb26696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "WEIGHT_BY_SOURCE = { \"auto\": 1.0, \"active\": 3.0 }\n",
    "CLICKS_PATH = PROJECT_ROOT / \"data\" / \"training_clicks.json\"\n",
    "\n",
    "def load_clicks():\n",
    "    if not CLICKS_PATH.exists():\n",
    "        return []\n",
    "    with open(str(CLICKS_PATH)) as f:\n",
    "        arr = json.load(f)\n",
    "    for c in arr:\n",
    "        if \"source\" not in c:\n",
    "            c[\"source\"] = \"auto\"\n",
    "    return arr\n",
    "\n",
    "def save_clicks(clicks):\n",
    "    CLICKS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(str(CLICKS_PATH), \"w\") as f:\n",
    "        json.dump(clicks, f)\n",
    "    print(f\"[saved] {len(clicks)} clicks -> {str(CLICKS_PATH)}\")\n",
    "\n",
    "def dedupe_clicks(clicks):\n",
    "    seen = set(); out = []\n",
    "    for c in clicks:\n",
    "        key = (c[\"fname\"], int(c[\"x\"]), int(c[\"y\"]))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key); out.append(c)\n",
    "    return out\n",
    "\n",
    "CLICK_SAMPLES = dedupe_clicks((globals().get(\"CLICK_SAMPLES\") or []) + load_clicks())\n",
    "save_clicks(CLICK_SAMPLES)\n",
    "print(\"Clicks by source:\", {s: sum(1 for c in CLICK_SAMPLES if c[\"source\"]==s) \n",
    "                            for s in set([c[\"source\"] for c in CLICK_SAMPLES])})\n",
    "\n",
    "rgb_map = {f: img for f, img in images}\n",
    "\n",
    "def build_training_xy_weighted(clicks):\n",
    "    X_list, y_list, g_list, w_list = [], [], [], []\n",
    "    for c in clicks:\n",
    "        fname, x, y, lbl = c[\"fname\"], int(c[\"x\"]), int(c[\"y\"]), int(c[\"label\"])\n",
    "        src  = c.get(\"source\", \"auto\")\n",
    "        if 'FEATURES' in globals() and fname in FEATURES:\n",
    "            F, H, W, C = FEATURES[fname]\n",
    "        else:\n",
    "            img_rgb = rgb_map[fname]\n",
    "            gray_eq = get_gray_eq(fname)\n",
    "            F = feature_stack(img_rgb, gray_eq); H, W, C = F.shape\n",
    "        if 0 <= x < W and 0 <= y < H:\n",
    "            X_list.append(F[y, x, :]); y_list.append(lbl); g_list.append(fname)\n",
    "            w_list.append(float(WEIGHT_BY_SOURCE.get(src, 1.0)))\n",
    "    X = np.array(X_list, dtype=np.float32)\n",
    "    y = np.array(y_list, dtype=np.uint8)\n",
    "    groups = np.array(g_list)\n",
    "    weights = np.array(w_list, dtype=np.float32)\n",
    "    return X, y, groups, weights\n",
    "\n",
    "X, y, groups, weights = build_training_xy_weighted(CLICK_SAMPLES)\n",
    "print(\"X:\", X.shape, \"| y:\", y.shape, \"| groups:\", len(groups), \"| weights range:\", (weights.min(), weights.max()))\n",
    "print(\"Label counts:\", Counter(y.tolist()))\n",
    "assert len(np.unique(y)) == 2, \"Need both classes in clicks (forest and non-forest).\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbceb44",
   "metadata": {},
   "source": [
    "# Cell 11: Train RF & Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06595b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, f1_score\n",
    "import numpy as np, os, cv2\n",
    "\n",
    "if 'otsu_map' not in globals():\n",
    "    otsu_map = {f: m for f, m in otsu_results}\n",
    "if 'km_map' not in globals():\n",
    "    km_map   = {f: m for f, m in kmeans_results}\n",
    "\n",
    "def forest_fraction(mask_u8):\n",
    "    return (mask_u8 > 0).sum() / mask_u8.size\n",
    "\n",
    "def baseline_forest_fraction(fname, alpha=0.8):\n",
    "    \"\"\"\n",
    "    Heuristic target fraction using Otsu (dominant) + KM (only if not extreme).\n",
    "    Clamped to [0.45, 0.60].\n",
    "    \"\"\"\n",
    "    f_otsu = forest_fraction(otsu_map[fname]) if fname in otsu_map else None\n",
    "    f_km   = forest_fraction(km_map[fname])   if fname in km_map   else None\n",
    "    if f_otsu is None and f_km is None:\n",
    "        tgt = 0.50\n",
    "    elif f_km is None or (f_km < 0.05 or f_km > 0.75):\n",
    "        tgt = f_otsu if f_otsu is not None else 0.50\n",
    "    else:\n",
    "        tgt = alpha * f_otsu + (1.0 - alpha) * f_km\n",
    "    return float(np.clip(tgt, 0.45, 0.60))\n",
    "\n",
    "def light_clean(mask_u8):\n",
    "    return clean_mask(mask_u8, min_area=150, k=3)\n",
    "\n",
    "def frac_after_clean(p_hw, thr):\n",
    "    m = ((p_hw >= thr).astype(np.uint8) * 255)\n",
    "    m = light_clean(m)\n",
    "    return forest_fraction(m)\n",
    "\n",
    "def find_thr_for_target(p_hw, tgt, lo=0.10, hi=0.90, tol=0.005, max_iter=18):\n",
    "    \"\"\"\n",
    "    Binary search a threshold so that fraction_after_clean(thr) ~ tgt.\n",
    "    Returns (thr_found, frac_found).\n",
    "    \"\"\"\n",
    "    f_lo = frac_after_clean(p_hw, lo)\n",
    "    f_hi = frac_after_clean(p_hw, hi)\n",
    "    if f_lo < tgt and f_hi < tgt:\n",
    "        return lo, f_lo\n",
    "    if f_lo > tgt and f_hi > tgt:\n",
    "        return hi, f_hi\n",
    "    for _ in range(max_iter):\n",
    "        mid = 0.5 * (lo + hi)\n",
    "        f_mid = frac_after_clean(p_hw, mid)\n",
    "        if abs(f_mid - tgt) <= tol:\n",
    "            return mid, f_mid\n",
    "        if f_mid > tgt:\n",
    "            lo, f_lo = mid, f_mid\n",
    "        else:\n",
    "            hi, f_hi = mid, f_mid\n",
    "    mid = 0.5 * (lo + hi)\n",
    "    return mid, frac_after_clean(p_hw, mid)\n",
    "\n",
    "def train_rf_grouped(X, y, groups, weights, threshold_by_f1=True):\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.33, random_state=42)\n",
    "    tr_idx, te_idx = next(gss.split(X, y, groups))\n",
    "    X_tr, X_te = X[tr_idx], X[te_idx]\n",
    "    y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "    w_tr       = weights[tr_idx]\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        class_weight=\"balanced\",\n",
    "        max_features=0.5,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_tr, y_tr, sample_weight=w_tr)\n",
    "    print(classification_report(y_te, clf.predict(X_te), digits=3))\n",
    "\n",
    "    thr = 0.5\n",
    "    if threshold_by_f1 and hasattr(clf, \"predict_proba\"):\n",
    "        proba = clf.predict_proba(X_te)[:, 1]\n",
    "        prec, rec, t = precision_recall_curve(y_te, proba)\n",
    "        if len(t):\n",
    "            f1s = [f1_score(y_te, (proba >= tt).astype(int)) for tt in t]\n",
    "            thr = float(t[int(np.argmax(f1s))])\n",
    "        else:\n",
    "            thr = 0.5\n",
    "    thr = float(np.clip(thr, 0.25, 0.70))  \n",
    "    print(f\"Chosen threshold (global, clamped): {thr:.3f}\")\n",
    "    return clf, thr\n",
    "\n",
    "clf, best_thr = train_rf_grouped(X, y, groups, weights)\n",
    "\n",
    "RESULTS_RF = os.path.join(RESULTS_ROOT, \"random_forest_hybrid\")\n",
    "os.makedirs(RESULTS_RF, exist_ok=True)\n",
    "rf_results = []\n",
    "\n",
    "print(\"\\nPer-image thresholds and fractions (post-clean):\")\n",
    "print(\"fname, tgt, thr_img, frac_rf\")\n",
    "\n",
    "for fname, img_rgb in images:\n",
    "    if 'FEATURES' in globals() and fname in FEATURES:\n",
    "        F, H, W, C = FEATURES[fname]\n",
    "    else:\n",
    "        gray_eq = get_gray_eq(fname)\n",
    "        F = feature_stack(img_rgb, gray_eq); H, W, C = F.shape\n",
    "\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        p = clf.predict_proba(F.reshape(-1, C).astype(np.float32))[:, 1].reshape(H, W)\n",
    "\n",
    "        tgt = baseline_forest_fraction(fname)\n",
    "        thr_img, _ = find_thr_for_target(p, tgt, lo=0.10, hi=0.90, tol=0.003, max_iter=20)\n",
    "\n",
    "        pred01 = (p >= thr_img).astype(np.uint8)\n",
    "        pred = (pred01 * 255).astype(np.uint8)\n",
    "        pred = light_clean(pred)\n",
    "    else:\n",
    "        tgt, thr_img = np.nan, np.nan\n",
    "        pred = (clf.predict(F.reshape(-1, C)).astype(np.uint8).reshape(H, W) * 255)\n",
    "        pred = light_clean(pred)\n",
    "\n",
    "    rf_results.append((fname, pred))\n",
    "\n",
    "    out_path = os.path.join(RESULTS_RF, f\"{os.path.splitext(fname)[0]}_rf_mask.png\")\n",
    "    cv2.imwrite(out_path, pred)\n",
    "\n",
    "    thr_str = f\"{thr_img:.3f}\" if (isinstance(thr_img, (float, np.floating)) and not np.isnan(thr_img)) else \"n/a\"\n",
    "    print(f\"{fname}, {tgt:.3f}, {thr_str}, {forest_fraction(pred):.3f}\")\n",
    "\n",
    "print(f\"\\n[done] RF hybrid masks -> {RESULTS_RF}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139011b4",
   "metadata": {},
   "source": [
    "# Cell 12: Refine RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52477fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "RESULTS_RF_REFINED = RESULTS_ROOT / \"random_forest_refined\"\n",
    "RESULTS_RF_REFINED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def fill_small_holes(m01, max_area=1500):\n",
    "    inv = 1 - m01\n",
    "    h, w = inv.shape\n",
    "    ff = inv.copy()\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "    cv2.floodFill(ff, mask, (0, 0), 1)\n",
    "    holes = (1 - ff).astype(np.uint8)\n",
    "\n",
    "    num, lab, stats, _ = cv2.connectedComponentsWithStats(holes, connectivity=8)\n",
    "    keep = np.zeros_like(holes, np.uint8)\n",
    "    for i in range(1, num):\n",
    "        if stats[i, cv2.CC_STAT_AREA] <= max_area:\n",
    "            keep[lab == i] = 1\n",
    "    return np.clip(m01 + keep, 0, 1)\n",
    "\n",
    "def refine_mask(mask_u8, border_pad=10, min_area=800, close_len=7, open_len=3, hole_max=1500):\n",
    "    m = (mask_u8 > 0).astype(np.uint8)\n",
    "    if min(m.shape) > 2 * border_pad:\n",
    "        m[:border_pad, :] = 0; m[-border_pad:, :] = 0\n",
    "        m[:, :border_pad] = 0; m[:, -border_pad:] = 0\n",
    "\n",
    "    kh = cv2.getStructuringElement(cv2.MORPH_RECT, (close_len, 1))\n",
    "    kv = cv2.getStructuringElement(cv2.MORPH_RECT, (1, close_len))\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kh, iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kv, iterations=1)\n",
    "\n",
    "    m = fill_small_holes(m, max_area=hole_max)\n",
    "\n",
    "    kh2 = cv2.getStructuringElement(cv2.MORPH_RECT, (open_len, 1))\n",
    "    kv2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1, open_len))\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN, kh2, iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN, kv2, iterations=1)\n",
    "\n",
    "    m = clean_mask((m * 255).astype(np.uint8), min_area=min_area, k=3)\n",
    "    return m\n",
    "\n",
    "def forest_fraction(mask_u8):\n",
    "    return (mask_u8 > 0).sum() / mask_u8.size\n",
    "\n",
    "rf_refined_results = []\n",
    "print(\"Refined fractions per image:\")\n",
    "for fname, pred in rf_results:\n",
    "    refined = refine_mask(\n",
    "        pred,\n",
    "        border_pad=10,\n",
    "        min_area=800,\n",
    "        close_len=7,\n",
    "        open_len=3,\n",
    "        hole_max=1500\n",
    "    )\n",
    "    rf_refined_results.append((fname, refined))\n",
    "    cv2.imwrite(str(RESULTS_RF_REFINED / f\"{Path(fname).stem}_rf_refined.png\"), refined)\n",
    "    print(f\"  {fname}: {forest_fraction(refined):.3f}\")\n",
    "\n",
    "print(f\"Refined RF masks saved to: {RESULTS_RF_REFINED}\")\n",
    "\n",
    "FIG_DIR = RESULTS_RF_REFINED / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for (fname, img_rgb), (_, rf_raw), (_, rf_ref) in zip(images, rf_results, rf_refined_results):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(14, 4), constrained_layout=True)\n",
    "    ax[0].imshow(img_rgb);  ax[0].set_title(fname);   ax[0].axis(\"off\")\n",
    "    ax[1].imshow(rf_raw, cmap=\"gray\"); ax[1].set_title(\"RF (post-clean)\"); ax[1].axis(\"off\")\n",
    "    ax[2].imshow(rf_ref, cmap=\"gray\"); ax[2].set_title(\"RF refined\"); ax[2].axis(\"off\")\n",
    "    fig.savefig(str(FIG_DIR / f\"{Path(fname).stem}_rf_quickpeek.png\"), dpi=200)\n",
    "    display(fig)  \n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Saved quick-peek panels -> {FIG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11664c1",
   "metadata": {},
   "source": [
    "# Cell 13: Overlay Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_mask(img_rgb, mask_u8, alpha=0.45, color=(60, 200, 60), resize_to=\"image\"):\n",
    "    mask = (mask_u8 > 0).astype(np.uint8)\n",
    "    Hi, Wi = img_rgb.shape[:2]\n",
    "    Hm, Wm = mask.shape[:2]\n",
    "    if resize_to == \"image\" and (Hi, Wi) != (Hm, Wm):\n",
    "        mask = cv2.resize(mask, (Wi, Hi), interpolation=cv2.INTER_NEAREST)\n",
    "    elif resize_to == \"mask\" and (Hi, Wi) != (Hm, Wm):\n",
    "        img_rgb = cv2.resize(img_rgb, (Wm, Hm), interpolation=cv2.INTER_AREA)\n",
    "    ov = img_rgb.copy().astype(np.float32)\n",
    "    ov[mask.astype(bool)] = ov[mask.astype(bool)] * (1.0 - alpha) + np.array(color, dtype=np.float32) * alpha\n",
    "    return ov.astype(np.uint8)\n",
    "\n",
    "rgb_map = {f: img for f, img in images}\n",
    "rf_ref_map = {f: m for f, m in rf_refined_results}\n",
    "\n",
    "for fname, rf_ref in rf_ref_map.items():\n",
    "    img_rgb = rgb_map[fname]\n",
    "    blend = overlay_mask(img_rgb, rf_ref, alpha=0.45, color=(60, 200, 60), resize_to=\"image\")\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(blend); plt.title(f\"{fname} • RF refined overlay\")\n",
    "    plt.axis(\"off\"); plt.show(); plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beedd5ad",
   "metadata": {},
   "source": [
    "# Cell 14: Supress Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_background_mask(gray_eq, high_pct=97, min_area=1000, dilate_k=9):\n",
    "    g = ensure_uint8(gray_eq)\n",
    "    thr = np.clip(int(np.percentile(g, high_pct)), 235, 252)\n",
    "    white = (g >= thr).astype(np.uint8)\n",
    "    white = cv2.morphologyEx(white, cv2.MORPH_OPEN, np.ones((3,3), np.uint8), iterations=1)\n",
    "\n",
    "    num, lab, stats, _ = cv2.connectedComponentsWithStats(white, connectivity=8)\n",
    "    H, W = g.shape\n",
    "    paper = np.zeros_like(white)\n",
    "    for i in range(1, num):\n",
    "        x, y, w_i, h_i, area = stats[i]\n",
    "        touches_border = (x == 0) or (y == 0) or (x + w_i >= W-1) or (y + h_i >= H-1)\n",
    "        if touches_border and area >= min_area:\n",
    "            paper[lab == i] = 1\n",
    "\n",
    "    if dilate_k:\n",
    "        paper = cv2.dilate(paper, np.ones((dilate_k, dilate_k), np.uint8), iterations=1)\n",
    "\n",
    "    content = ((1 - paper) * 255).astype(np.uint8)\n",
    "    return content\n",
    "\n",
    "rf_borderfixed_results = []\n",
    "for fname, rf_mask in rf_refined_results:\n",
    "    gray_eq = get_gray_eq(fname)\n",
    "    content = paper_background_mask(gray_eq)\n",
    "    rf_fixed = cv2.bitwise_and(rf_mask, content)\n",
    "    rf_borderfixed_results.append((fname, rf_fixed))\n",
    "\n",
    "for fname, rf_fixed in rf_borderfixed_results:\n",
    "    blend = overlay_mask(rgb_map[fname], rf_fixed, alpha=0.45, color=(60,200,60), resize_to=\"image\")\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(blend); plt.title(f\"{fname} • RF overlay (border suppressed)\")\n",
    "    plt.axis(\"off\"); plt.show(); plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d435a",
   "metadata": {},
   "source": [
    "# Cell 15: Final Comparisons vs Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a39c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_fraction(mask): \n",
    "    return (mask > 0).sum() / mask.size\n",
    "\n",
    "def iou(a, b):\n",
    "    A, B = (a > 0), (b > 0)\n",
    "    inter = np.logical_and(A, B).sum()\n",
    "    union = np.logical_or(A, B).sum()\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "otsu_map_final   = {f: m for f, m in otsu_results}\n",
    "edges_map_final  = {f: m for f, m in edges_results}\n",
    "km_map_final     = {f: m for f, m in kmeans_results}\n",
    "rf_ref_map_final = {f: m for f, m in rf_refined_results}\n",
    "rf_raw_map_final = {f: m for f, m in rf_results}\n",
    "\n",
    "for fname, img_rgb in images:\n",
    "    if fname not in rf_ref_map_final:\n",
    "        print(f\"[skip] {fname}: no RF refined mask found.\")\n",
    "        continue\n",
    "\n",
    "    otsu  = otsu_map_final.get(fname)\n",
    "    edges = edges_map_final.get(fname)\n",
    "    km    = km_map_final.get(fname)\n",
    "    rfref = rf_ref_map_final[fname]\n",
    "\n",
    "    print(f\"\\n{fname}\")\n",
    "    print(\"  Fractions  | Otsu {:.3f} | Canny {:.3f} | KM {:.3f} | RF* {:.3f}\"\n",
    "          .format(forest_fraction(otsu), forest_fraction(edges), forest_fraction(km), forest_fraction(rfref)))\n",
    "    print(\"  IoU vs RF* | Otsu {:.3f} | Canny {:.3f} | KM {:.3f}\"\n",
    "          .format(iou(rfref, otsu), iou(rfref, edges), iou(rfref, km)))\n",
    "    if fname in rf_raw_map_final:\n",
    "        print(\"  RF(raw) vs RF* IoU: {:.3f}\".format(iou(rf_raw_map_final[fname], rfref)))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(15, 4))\n",
    "    ax[0].imshow(img_rgb); ax[0].set_title(\"Original\");    ax[0].axis(\"off\")\n",
    "    ax[1].imshow(otsu,  cmap=\"gray\"); ax[1].set_title(\"Otsu\");       ax[1].axis(\"off\")\n",
    "    ax[2].imshow(edges, cmap=\"gray\"); ax[2].set_title(\"Canny\");      ax[2].axis(\"off\")\n",
    "    ax[3].imshow(km,    cmap=\"gray\"); ax[3].set_title(\"KMeans\");     ax[3].axis(\"off\")\n",
    "    ax[4].imshow(rfref, cmap=\"gray\"); ax[4].set_title(\"RF refined\"); ax[4].axis(\"off\")\n",
    "    plt.suptitle(fname + \"   (RF* = RF refined)\")\n",
    "    plt.show(); plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c72c3e",
   "metadata": {},
   "source": [
    "# Cell 16: Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ENABLE_ACTIVE:\n",
    "    print(\"[info] Active learning is disabled (ENABLE_ACTIVE=0). Skipping Cells 17–19.\")\n",
    "    \n",
    "if ENABLE_ACTIVE:\n",
    "    UNCERTAIN_PER_IMAGE = 50\n",
    "    UNCERTAIN_MIN_DIST  = 12\n",
    "\n",
    "    def sample_uncertain_points_for_image(fname, img_rgb, clf, k=UNCERTAIN_PER_IMAGE, min_dist=UNCERTAIN_MIN_DIST):\n",
    "        if 'FEATURES' in globals() and fname in FEATURES:\n",
    "            F, H, W, C = FEATURES[fname]\n",
    "        else:\n",
    "            F = feature_stack(img_rgb, get_gray_eq(fname)); H, W, C = F.shape\n",
    "        X_all = F.reshape(-1, C).astype(np.float32)\n",
    "        if not hasattr(clf, \"predict_proba\"):\n",
    "            return []\n",
    "        p = clf.predict_proba(X_all)[:,1].reshape(H, W)\n",
    "        u = np.abs(p - 0.5)\n",
    "        ys, xs = np.unravel_index(np.argsort(u, axis=None), u.shape)\n",
    "\n",
    "        chosen = []\n",
    "        for y0, x0 in zip(ys, xs):\n",
    "            if len(chosen) >= k: break\n",
    "            if all((xc - x0)**2 + (yc - y0)**2 >= (min_dist**2) for (xc, yc) in chosen):\n",
    "                chosen.append((x0, y0))\n",
    "        return [{\"fname\": fname, \"x\": int(x), \"y\": int(y), \"label\": None, \"source\": \"active_suggested\"} \n",
    "                for (x,y) in chosen]\n",
    "\n",
    "    ACTIVE_PROPOSALS = []\n",
    "    for fname, img_rgb in images:\n",
    "        ACTIVE_PROPOSALS += sample_uncertain_points_for_image(fname, img_rgb, clf,\n",
    "                                k=UNCERTAIN_PER_IMAGE, min_dist=UNCERTAIN_MIN_DIST)\n",
    "\n",
    "    print(f\"Proposed {len(ACTIVE_PROPOSALS)} uncertain points across {len(images)} images.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef60cc2",
   "metadata": {},
   "source": [
    "# Cell 17: Active Learning UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_ACTIVE:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "\n",
    "    PATCH_VIEW = 48  \n",
    "\n",
    "    def get_patch(gray, x, y, half=PATCH_VIEW//2):\n",
    "        H, W = gray.shape\n",
    "        x0, y0 = max(0, x-half), max(0, y-half)\n",
    "        x1, y1 = min(W, x+half), min(H, y+half)\n",
    "        patch = gray[y0:y1, x0:x1]\n",
    "        out = np.zeros((2*half, 2*half), dtype=gray.dtype)\n",
    "        out[:patch.shape[0], :patch.shape[1]] = patch\n",
    "        return out\n",
    "\n",
    "    def label_active_proposals(proposals, max_to_label=100):\n",
    "        global CLICK_SAMPLES\n",
    "        count = 0\n",
    "        status = widgets.Label()\n",
    "        btn_f = widgets.Button(description=\"Forest\", button_style=\"success\")\n",
    "        btn_n = widgets.Button(description=\"Non-forest\", button_style=\"danger\")\n",
    "        btn_s = widgets.Button(description=\"Skip\", button_style=\"\")\n",
    "        display(widgets.HBox([btn_f, btn_n, btn_s]), status)\n",
    "\n",
    "        i = 0\n",
    "        fig, ax = plt.subplots(figsize=(3.3,3.3))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        def show_current():\n",
    "            nonlocal i\n",
    "            if i >= len(proposals) or count >= max_to_label:\n",
    "                status.value = f\"Done. Labeled {count} points.\"\n",
    "                return\n",
    "            pr = proposals[i]\n",
    "            g = get_gray_eq(pr[\"fname\"])\n",
    "            patch = get_patch(g, pr[\"x\"], pr[\"y\"], half=PATCH_VIEW//2)\n",
    "            ax.clear()\n",
    "            ax.imshow(patch, cmap=\"gray\"); ax.axis(\"off\")\n",
    "            ax.set_title(f'{pr[\"fname\"]} @ ({pr[\"x\"]},{pr[\"y\"]})')\n",
    "            fig.canvas.draw_idle()\n",
    "            status.value = f\"{i+1}/{min(len(proposals), max_to_label)}\"\n",
    "\n",
    "        def _commit(lbl):\n",
    "            nonlocal i, count\n",
    "            pr = proposals[i]\n",
    "            if lbl is not None:\n",
    "                CLICK_SAMPLES.append({\"fname\": pr[\"fname\"], \"x\": pr[\"x\"], \"y\": pr[\"y\"],\n",
    "                                      \"label\": int(lbl), \"source\": \"active\"})\n",
    "            i += 1\n",
    "            if lbl is not None: count += 1\n",
    "            show_current()\n",
    "\n",
    "        btn_f.on_click(lambda _: _commit(1))\n",
    "        btn_n.on_click(lambda _: _commit(0))\n",
    "        btn_s.on_click(lambda _: _commit(None))\n",
    "\n",
    "        show_current()\n",
    "\n",
    "    label_active_proposals(ACTIVE_PROPOSALS, max_to_label=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892c061",
   "metadata": {},
   "source": [
    "# Cell 18: Save, Retrain, Reapply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ea135",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_ACTIVE:\n",
    "    CLICK_SAMPLES = dedupe_clicks(CLICK_SAMPLES)\n",
    "    save_clicks(CLICK_SAMPLES)\n",
    "\n",
    "    X, y, groups, weights = build_training_xy_weighted(CLICK_SAMPLES)\n",
    "    clf, best_thr = train_rf_grouped(X, y, groups, weights)\n",
    "\n",
    "    RESULTS_RF = os.path.join(RESULTS_ROOT, \"random_forest_hybrid\")\n",
    "    os.makedirs(RESULTS_RF, exist_ok=True)\n",
    "    rf_results = []\n",
    "\n",
    "    for fname, img_rgb in images:\n",
    "        if 'FEATURES' in globals() and fname in FEATURES:\n",
    "            F, H, W, C = FEATURES[fname]\n",
    "        else:\n",
    "            F = feature_stack(img_rgb, get_gray_eq(fname)); H, W, C = F.shape\n",
    "\n",
    "        X_all = F.reshape(-1, C).astype(np.float32)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            pred01 = (clf.predict_proba(X_all)[:,1] >= best_thr).astype(np.uint8)\n",
    "        else:\n",
    "            pred01 = clf.predict(X_all).astype(np.uint8)\n",
    "\n",
    "        pred = (pred01.reshape(H, W) * 255).astype(np.uint8)\n",
    "        pred = clean_mask(pred)\n",
    "        rf_results.append((fname, pred))\n",
    "        cv2.imwrite(os.path.join(RESULTS_RF, f\"{os.path.splitext(fname)[0]}_rf_mask.png\"), pred)\n",
    "\n",
    "    rf_refined_results = []\n",
    "    for fname, pred in rf_results:\n",
    "        refined = refine_mask(pred, border_pad=12, min_area=800, close_len=15, open_len=3, hole_max=2000)\n",
    "        rf_refined_results.append((fname, refined))\n",
    "        cv2.imwrite(os.path.join(RESULTS_RF_REFINED, f\"{os.path.splitext(fname)[0]}_rf_refined.png\"), refined)\n",
    "\n",
    "    print(\"[retrained] Hybrid RF masks updated and refined.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
